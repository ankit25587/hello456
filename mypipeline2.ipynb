{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3d42adc-fe87-4317-9db7-7f08e62a4196",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "import kfp\n",
    "from kfp import dsl\n",
    "from kfp.v2 import compiler\n",
    "from kfp.v2.dsl import component\n",
    "from kfp.v2.google.client import AIPlatformClient\n",
    "from kfp.v2.dsl import (Artifact,\n",
    "                        Dataset,\n",
    "                        Input,\n",
    "                        Model,\n",
    "                        Output,\n",
    "                        Metrics,\n",
    "                        component)\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b48b5b9-a7b7-4ac7-bf14-5bd44183e382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PATH=/opt/conda/bin:/opt/conda/condabin:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/home/jupyter/.local/bin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'gs://vertex-ai-tutorial-368805-bucket/pipeline_root3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This shell-command outputs default project\n",
    "shell_output = !gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "PROJECT_ID = shell_output[0]\n",
    "REGION = \"us-central1\"\n",
    "BUCKET_NAME = \"gs://vertex-ai-tutorial-368805-bucket\"\n",
    "\n",
    "PATH=%env PATH\n",
    "%env PATH={PATH}:/home/jupyter/.local/bin\n",
    "USER = \"sam_oz\"\n",
    "PIPELINE_ROOT = \"{}/pipeline_root3\".format(BUCKET_NAME)\n",
    "# If there are multiple users, it is better to use username in path:\n",
    "# PIPELINE_ROOT = \"{}/pipeline_root/{}\".format(BUCKET_NAME, USER)\n",
    "\n",
    "PIPELINE_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bc0921e-4762-4b97-990d-650665e744dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and Split Data from BQ Table\n",
    "@component(packages_to_install=[\"google-cloud-bigquery\", \"pandas\", \"pyarrow\", \"sklearn\"]) \n",
    "def get_data(dataset_train: Output[Dataset],dataset_test: Output[Dataset]):\n",
    "    '''Query data warehouse and return dataframe'''\n",
    "    from google.cloud import bigquery\n",
    "    client = bigquery.Client()\n",
    "    project = \"samet-sandbox2\"\n",
    "    dataset_id = \"regular_dataset\"\n",
    "\n",
    "    dataset_ref = bigquery.DatasetReference(project, dataset_id)\n",
    "    table_ref = dataset_ref.table(\"IOT_Data\")\n",
    "    table = client.get_table(table_ref)\n",
    "\n",
    "    data = client.list_rows(table).to_dataframe()\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split as tts\n",
    "    train, test = tts(data, test_size=0.3)\n",
    "    \n",
    "    train.to_csv(dataset_train.path)\n",
    "    test.to_csv(dataset_test.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e1992cb-5658-46c3-8beb-a24ec335b38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(packages_to_install = [\"pandas\",\"sklearn\",\"xgboost\"],)\n",
    "def train_xgb_model(\n",
    "    dataset: Input[Dataset],\n",
    "    model_artifact: Output[Model]):\n",
    "    \n",
    "    from xgboost import XGBRegressor\n",
    "    import pandas as pd\n",
    "    # Get data from path: get_data().outputs[\"dataset_train\"]\n",
    "    data = pd.read_csv(dataset.path)\n",
    "\n",
    "    # Instantiate algorithm\n",
    "    model = XGBRegressor(\n",
    "    n_estimators=150,\n",
    "    reg_lambda=15,\n",
    "    gamma=0,\n",
    "    max_depth=3)\n",
    "    \n",
    "    X_train = data.drop(columns=[\"t0\"])\n",
    "    y_train = data['t0']\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train,y_train,)\n",
    "    \n",
    "    # Calculate score.First argument is X, second is Y. \n",
    "    # Returns the coefficient of determination R^2 of the prediction.\n",
    "    score = model.score(\n",
    "        data.drop(columns=[\"t0\"]),\n",
    "        data['t0'],)\n",
    "    \n",
    "    # This functions output is a Model; which we defined as \"Output[Model]\" in functions parameters.\n",
    "    # We can reach model's metadata.\n",
    "    model_artifact.metadata[\"train_score\"] = float(score) # model_artifact is Output[Model]\n",
    "    model_artifact.metadata[\"framework\"] = \"XGBoost\" # We define this metadata.\n",
    "    \n",
    "    model.save_model(model_artifact.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86ca248a-3e75-431e-84aa-65f452f60b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(packages_to_install = [\"pandas\",\"sklearn\",\"xgboost\",\"numpy\"],)\n",
    "def eval_model(\n",
    "    test_set: Input[Dataset],\n",
    "    xgb_model: Input[Model],\n",
    "    metrics: Output[Metrics]\n",
    "):\n",
    "    from xgboost import XGBRegressor\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    data = pd.read_csv(test_set.path)\n",
    "    model = XGBRegressor()\n",
    "    model.load_model(xgb_model.path)\n",
    "    \n",
    "    X_test = data.drop(columns=[\"t0\"])\n",
    "    y_test = data['t0']\n",
    "    \n",
    "    score = model.score(X_test,y_test)\n",
    "    y_pred = model.predict(X_test)\n",
    "    from sklearn.metrics import mean_absolute_error\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mape = np.sum(np.abs(y_test - y_pred) / y_test)\n",
    "    metrics.log_metric(\"Mean Absolute Error\", mae)\n",
    "    metrics.log_metric(\"R-Square\", score)\n",
    "    metrics.log_metric(\"MAPE\", mape)\n",
    "    \n",
    "    xgb_model.metadata[\"test_score\"] = float(score)\n",
    "    xgb_model.metadata[\"mae_score\"] = float(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbc5bf0c-ef39-44ef-9948-2cab5dd67874",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/kfp/v2/compiler/compiler.py:1293: FutureWarning: APIs imported from the v1 namespace (e.g. kfp.dsl, kfp.components, etc) will not be supported by the v2 compiler since v2.0.0\n",
      "  category=FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "@dsl.pipeline(\n",
    "    # Default pipeline root. You can override it when submitting the pipeline.\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    # A name for the pipeline. Use to determine the pipeline Context.\n",
    "    name=\"pipeline-test-1\",\n",
    ")\n",
    "def pipeline():\n",
    "    dataset_op = get_data()\n",
    "    train_op = train_xgb_model(dataset_op.outputs[\"dataset_train\"])\n",
    "    eval_op = eval_model(test_set=dataset_op.outputs[\"dataset_test\"],xgb_model=train_op.outputs[\"model_artifact\"])\n",
    "    \n",
    "compiler.Compiler().compile(pipeline_func=pipeline,\n",
    "        package_path='xgb_pipe.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cb250ca-073f-40bf-bda7-a04c6ac54500",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/kfp/v2/google/client/client.py:173: FutureWarning: AIPlatformClient will be deprecated in v2.0.0. Please use PipelineJob https://googleapis.dev/python/aiplatform/latest/_modules/google/cloud/aiplatform/pipeline_jobs.html in Vertex SDK. Install the SDK using \"pip install google-cloud-aiplatform\"\n",
      "  category=FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "See the Pipeline job <a href=\"https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/pipeline-test-1-20221205114708?project=vertex-ai-tutorial-368805\" target=\"_blank\" >here</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from kfp.v2.google.client import AIPlatformClient\n",
    "\n",
    "api_client = AIPlatformClient(project_id=PROJECT_ID, region=REGION)\n",
    "\n",
    "response = api_client.create_run_from_job_spec(\n",
    "job_spec_path=\"xgb_pipe.json\",\n",
    "# pipeline_root=PIPELINE_ROOT # this argument is necessary if you did not specify PIPELINE_ROOT as part of the pipeline definition.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086cc0a4-20ea-4722-ae2f-1a80365e5949",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m100",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m100"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
